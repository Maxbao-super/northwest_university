人工智能的伦理思考

 案例：

①AlphaGo战胜国手

②无人驾驶撞死人。



人工智能造福人类还是威胁人类

案例：

①造福：facebook插曲，一台机器学习设备自发的绕过程序设计师主动与其他AI设备建立了语言联系。

②威胁：Google AI能自动进行翻译。

人工智能威胁论 霍金、埃隆•马斯克

人工智能是人类文明的最大威胁，它们比核武器更加危险

全面化人工智能可能意味着人类的终结

人工智能可能引发第三次世界大战

人工智能的研究就仿佛是在召唤一个恶魔

人工智能造福论 李开复    马克•扎克伯格(facebook  CEO)

人类总是畏惧人工智能在未来会失控而伤害人类，但同时我们也应该看到另一方面人工智能真的能够挽救人类的生命

中间派 比尔•盖茨



人工智能带来的伦理困境

伦理：研究人与人、人与自然、人与社会的关系，以及处理这些关系的准则。

人工智能带来的新问题：跨人类伦理问题：人与机器之间的关系人与人、人与社会交互方式的改变安全、隐私、决策、法律

安全困境

① 超级智能与人工愚蠢

超级智能是指某些人工智能在某些特定领域拥有超级的能力，如计算速度，从而造成了某些不可控的后果。

超级智能往往存在一些“黑箱”般的不透明性。如对于深度学习算法。

人工愚蠢是人工智能的反义词，意指简单规则下的人工智能的失败。（纳什博弈）

②人身安全问题



③隐私安全问题



人工智能应遵循的伦理原则

